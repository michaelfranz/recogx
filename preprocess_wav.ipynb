{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess WAVs into mel-frequency cepstrum (MFC) JPEGs\n",
    "This script is used to convert audio files of the wav format into MFC images. The resulting images are used to train a CNN to recognise the speaker's gender. Credits: Most - practically all - the following functions were in copied from the project https://github.com/zhihanyang2022/gender_audio_classification by Zhihan Yang.\n",
    "Small adjustments were made so the code no longer depends on a function, which was deprecated in SciPy since SciPy version 1.3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-27T02:25:14.546881Z",
     "start_time": "2020-02-27T02:25:14.533643Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "import librosa\n",
    "import numpy as np\n",
    "import scipy.io.wavfile\n",
    "from skimage.transform import resize\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtain file paths of wav files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-27T01:45:39.535864Z",
     "start_time": "2020-02-27T01:45:39.530451Z"
    }
   },
   "outputs": [],
   "source": [
    "audio_dir = 'AudioMNIST'\n",
    "audio_meta_path = f'{audio_dir}/audioMNIST_meta.json' # audio meta data (labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-27T01:45:39.547669Z",
     "start_time": "2020-02-27T01:45:39.539703Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(audio_meta_path) as json_file:\n",
    "    audio_meta = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-27T01:45:39.569559Z",
     "start_time": "2020-02-27T01:45:39.553006Z"
    }
   },
   "outputs": [],
   "source": [
    "male_idxs, female_idxs = [], []\n",
    "for idx, info in audio_meta.items():\n",
    "    if info['gender'].lower() == 'male':\n",
    "        male_idxs.append(idx)\n",
    "    elif info['gender'].lower() == 'female':\n",
    "        female_idxs.append(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total male speakers: 48\n",
      "Total female speakers: 12\n"
     ]
    }
   ],
   "source": [
    "print(f'Total male speakers: {len(male_idxs)}\\nTotal female speakers: {len(female_idxs)}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-27T01:45:39.586694Z",
     "start_time": "2020-02-27T01:45:39.578440Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_wav_paths_from_speaker_indices(idxs):\n",
    "    wav_fpaths = []\n",
    "    for idx in idxs:\n",
    "        for fname in os.listdir(f'{audio_dir}/{idx}'):\n",
    "            wav_fpaths.append(f'{audio_dir}/{idx}/{fname}')\n",
    "    return wav_fpaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-27T01:45:39.841611Z",
     "start_time": "2020-02-27T01:45:39.595982Z"
    }
   },
   "outputs": [],
   "source": [
    "male_wav_fpaths = sorted(get_wav_paths_from_speaker_indices(male_idxs))\n",
    "female_wav_fpaths = sorted(get_wav_paths_from_speaker_indices(female_idxs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure same order across runs\n",
    "np.random.seed(13)\n",
    "np.random.shuffle(male_wav_fpaths)\n",
    "np.random.shuffle(female_wav_fpaths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "wav_fpaths = male_wav_fpaths + female_wav_fpaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AudioMNIST/08/8_08_17.wav', 'AudioMNIST/37/0_37_9.wav', 'AudioMNIST/35/5_35_8.wav', 'AudioMNIST/31/3_31_20.wav', 'AudioMNIST/24/9_24_18.wav', 'AudioMNIST/09/2_09_11.wav', 'AudioMNIST/15/4_15_20.wav', 'AudioMNIST/01/7_01_25.wav', 'AudioMNIST/38/5_38_28.wav', 'AudioMNIST/27/5_27_16.wav']\n"
     ]
    }
   ],
   "source": [
    "print(wav_fpaths[0:10])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-27T02:12:29.106045Z",
     "start_time": "2020-02-27T02:12:29.099451Z"
    }
   },
   "outputs": [],
   "source": [
    "def pad_input(input, target_len):\n",
    "    # CNN needs input to be same length. This function truncates input if too long; pads input with zeros if troo short\n",
    "    num_zeros_needed = target_len - len(input)\n",
    "    if num_zeros_needed > 0:\n",
    "        num_zeros_front = np.random.randint(num_zeros_needed)\n",
    "        num_zeros_back = num_zeros_needed - num_zeros_front\n",
    "        return np.pad(input, (num_zeros_front, num_zeros_back), mode='constant')\n",
    "    else:\n",
    "        return input[0: target_len]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-27T01:45:39.913573Z",
     "start_time": "2020-02-27T01:45:39.905660Z"
    }
   },
   "outputs": [],
   "source": [
    "kpre_emphasis_coeff = 0.97"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-27T01:45:39.925439Z",
     "start_time": "2020-02-27T01:45:39.919362Z"
    }
   },
   "outputs": [],
   "source": [
    "def pre_emphasis(input):\n",
    "    first_amp = input[0]\n",
    "    all_amps_without_first = input[1:]\n",
    "    all_amps_without_last = input[:-1]\n",
    "    emphasized_input = np.append(first_amp, all_amps_without_first - kpre_emphasis_coeff * all_amps_without_last)\n",
    "    return emphasized_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-27T01:45:39.939072Z",
     "start_time": "2020-02-27T01:45:39.932845Z"
    }
   },
   "outputs": [],
   "source": [
    "def pipeline(input):\n",
    "    \n",
    "    emphasized_input = pre_emphasis(input)\n",
    "    \n",
    "    # apply dft, mel filter banks, logging, dct and normalization\n",
    "    lifted_mfcc = librosa.feature.mfcc(\n",
    "        y=emphasized_input.astype(float),\n",
    "        sr=sample_rate, \n",
    "        n_mfcc=12, \n",
    "        dct_type=2, \n",
    "        norm='ortho', \n",
    "        lifter=22,\n",
    "        n_fft = int(sample_rate * 0.025),\n",
    "        hop_length= int(sample_rate * 0.01),\n",
    "        power=2,\n",
    "        center=False,\n",
    "        window='hann',\n",
    "        n_mels=40\n",
    "    )\n",
    "\n",
    "    return lifted_mfcc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtain max length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-27T02:10:05.826382Z",
     "start_time": "2020-02-27T02:10:05.814670Z"
    }
   },
   "outputs": [],
   "source": [
    "sample_rate = librosa.core.get_samplerate(wav_fpaths[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "48000"
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-27T02:09:56.856714Z",
     "start_time": "2020-02-27T02:09:56.839126Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def get_max_duration(filenames):\n",
    "    max_duration = 0\n",
    "    for path in tqdm_notebook(filenames):\n",
    "        duration = librosa.core.audio.get_duration(filename=path)\n",
    "        if duration > max_duration:\n",
    "            max_duration = duration\n",
    "    return max_duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-27T01:57:58.382200Z",
     "start_time": "2020-02-27T01:57:40.727153Z"
    }
   },
   "outputs": [],
   "source": [
    "# max_duration = get_max_duration(wav_fpaths) # this takes a while to run as processes 30k audio files\n",
    "max_duration = 0.9999583333333333"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "0.9999583333333333"
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-27T02:10:08.292887Z",
     "start_time": "2020-02-27T02:10:08.286744Z"
    }
   },
   "outputs": [],
   "source": [
    "max_samples = int(max_duration * sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "47998"
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output MFC JPEGs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "mfc_dataset_dir = 'mfc_dataset'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a one-to-one mapping between MFC JPEG names and WAV names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/24000 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a50341fd4e334dfca6f74ca7fa9c8920"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/6000 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "eaa5c9d9cf2743e892f8bbecf1c934bd"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "male_idxs_to_wav_fpaths = {}\n",
    "for i, fp in tqdm_notebook(enumerate(male_wav_fpaths), total=len(male_wav_fpaths)):\n",
    "    male_idxs_to_wav_fpaths[f'{mfc_dataset_dir}/male_{i}.jpg'] = fp\n",
    "\n",
    "female_idxs_to_wav_fpaths = {}\n",
    "for i, fp in tqdm_notebook(enumerate(female_wav_fpaths), total=len(female_wav_fpaths)):\n",
    "    female_idxs_to_wav_fpaths[f'{mfc_dataset_dir}/female_{i}.jpg'] = fp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('audio_to_mfc_maps/male_idxs_to_wav_fpaths.json', 'w+') as json_f:\n",
    "    json.dump(male_idxs_to_wav_fpaths, json_f)\n",
    "\n",
    "with open('audio_to_mfc_maps/female_idxs_to_wav_fpaths.json', 'w+') as json_f:\n",
    "    json.dump(female_idxs_to_wav_fpaths, json_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-27T02:44:57.437162Z",
     "start_time": "2020-02-27T02:31:55.586821Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/24000 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d18e749ba47442b7b40a8f2892868738"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from PIL import Image\n",
    "\n",
    "np.random.seed(1)\n",
    "for i, fp in tqdm_notebook(enumerate(male_wav_fpaths), total=len(male_wav_fpaths)):\n",
    "    _, input = scipy.io.wavfile.read(fp)\n",
    "    input = pad_input(input, target_len=max_samples)\n",
    "    mfc = pipeline(input)\n",
    "    mfc = (((mfc - mfc.min()) / (mfc.max() - mfc.min())) * 255.9).astype(np.uint8)\n",
    "    im = Image.fromarray(mfc)\n",
    "    im.save(f'{mfc_dataset_dir}/male_{i}.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/6000 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "42f59b7591384d11a755b88dccd94fd2"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "np.random.seed(2)\n",
    "for i, fp in tqdm_notebook(enumerate(female_wav_fpaths), total=len(female_wav_fpaths)):\n",
    "    _, input = scipy.io.wavfile.read(fp)  # faster than librosa\n",
    "    input = pad_input(input, target_len=max_samples)\n",
    "    mfc = pipeline(input)\n",
    "    mfc = (((mfc - mfc.min()) / (mfc.max() - mfc.min())) * 255.9).astype(np.uint8)\n",
    "    im = Image.fromarray(mfc)\n",
    "    im.save(f'{mfc_dataset_dir}/female_{i}.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
